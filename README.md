# ADS2025 Data Science Assignments

Welcome to the repository containing all assignments completed for the ADS2025 Data Science course. Each notebook delves into essential data science concepts and techniques, providing practical experience through hands-on projects.

## Overview

### Exploratory Data Analysis and Data Cleaning
- **Concepts Covered**:
  - Performing Exploratory Data Analysis (EDA)
  - Identifying and handling missing, invalid, or duplicate data
  - Data preprocessing and normalization techniques

### Data Visualization and Web Scraping
- **Concepts Covered**:
  - Creating various plots: pie charts, box plots, line charts, bar charts, scatter plots, and bubble charts
  - Implementing interactive visualizations using Plotly and Bokeh
  - Web scraping techniques to extract data from websites

### Feature Engineering
- **Concepts Covered**:
  - Generating new features through ratio calculations, binning, and combining existing features
  - Extracting features from date/time data
  - Feature selection using Mutual Information
  - Dimensionality reduction with Principal Component Analysis (PCA)

### Accuracy Measures
- **Concepts Covered**:
  - Regression metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), RÂ² Score
  - Classification metrics: Precision, Recall, F1-Score
  - Evaluating multi-class classification performance

### Regression Methods
- **Concepts Covered**:
  - Implementing Linear, Kernel, Logistic, Ridge, and LASSO Regression models
  - Understanding and applying the kernel trick for non-linear data

### Binary Classification Methods
- **Concepts Covered**:
  - Building classifiers: Logistic Regression, Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Decision Trees, Random Forests
  - Hyperparameter tuning and model evaluation
  - Regularization techniques to prevent overfitting

### Multiclass Classification Methods
- **Concepts Covered**:
  - Extending binary classifiers to multiclass problems
  - One-vs-Rest (OVR) and multinomial approaches
  - Boosting techniques: XGBoost, LightGBM, AdaBoost, CatBoost
  - Hyperparameter tuning using grid search

### Neural Networks
- **Concepts Covered**:
  - Designing and training Multilayer Perceptrons (MLP) using Scikit-Learn
  - Building feedforward neural networks with Keras and PyTorch
  - Implementing Recurrent Neural Networks (RNN) for time-series data

### Deep Neural Networks
- **Concepts Covered**:
  - Deep learning model optimization: tuning optimizers, learning rates, batch sizes, activation functions, and regularization techniques
  - Implementing dropout and weight initialization strategies
  - Understanding challenges in training deep neural networks

### Convolutional Neural Networks, Transfer Learning, and Data Augmentation
- **Concepts Covered**:
  - Building CNNs with Keras including multiple convolutional and pooling layers
  - Hyperparameter tuning of kernel size, stride, and pooling parameters
  - Implementing data augmentation using `ImageDataGenerator`
  - Performing transfer learning using pre-trained models like VGG19, ResNet, or EfficientNet
  - Analyzing the impact of receptive field size on model performance
  - Evaluation using 3-fold cross-validation

### Autoencoders and Generative AI
- **Concepts Covered**:
  - Implementing dense, convolutional, and denoising autoencoders
  - Creating and training GANs on CIFAR-10 for image generation
  - Using OpenAI APIs for multimodal generation (image, text, and speech)
  - Understanding adversarial training
  - Implementing Variational Autoencoders (VAEs) on Fashion MNIST

### Imbalanced Data and Explainable AI
- **Concepts Covered**:
  - Creating data processing pipelines with Pandas and Scikit-Learn
  - Handling imbalanced datasets with undersampling, oversampling, SMOTE, and class weighting
  - Integrating classifiers into data pipelines
  - Applying explainability techniques on CNNs: Grad-CAM, SHAP, LIME, and ELI5
  - Understanding and interpreting model decisions through visualization
